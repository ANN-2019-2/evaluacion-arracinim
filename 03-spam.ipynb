{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3lnWjvI83ix"
   },
   "source": [
    "# Filtado de mensajes spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La recepción de publicidad no deseada a traves mensajes de texto usando SMS (Short Message Service) es un problema que afecta a muchos usuarios de teléfonos móviles. El problema radica en que los usuarios deben pagar por los mesajes recibidos, y por este motivo resulta muy importante que las compañías prestadoras del servicio puedan filtrar mensajes indeseados antes de enviarlos a su destinatario final. Los mensajes tienen una longitud máxima de 160 caracteres, por lo que el texto resulta poco para realizar la clasificación, en comparación con textos más largos (como los emails). Adicionalmente, los errores de digitación dificultan el proceso de detección automática."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción del problema en términos de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tiene una muestra contiene 5574 mensajes en inglés, no codificados y clasificados como legítimos (ham) o spam (http://www.dt.fee.unicamp.br/~tiago/smsspamcollection/). La información está almacenada en el archivo `datos/spam-sms.zip`.El problema en términos de los datos consiste en clasificar si un mensaje SMS es legítico o spam, a partir del análisis de las palabras que contiente, partiendo del supuesto de que ciertas palabras que son más frecuentes dependiendo del tipo de mensaje. Esto implica que en la fase de preparación de los datos se deben extraer las palabras que contiene cada mensaje para poder realizar el análsis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aproximaciones posibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, se desea comparar los resultados de un modelo de redes neuronales artificiales y otras técnicas estadísticas para realizar la clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requerimientos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usted debe:\n",
    "\n",
    "* Preprocesar los datos para representarlos usando bag-of-words.\n",
    "\n",
    "\n",
    "* Construir un modelo de regresión logística como punto base para la comparación con otros modelos más complejos.\n",
    "\n",
    "\n",
    "* Construir un modelo de redes neuronales artificiales. Asimismo, debe determinar el número de neuronas en la capa o capas ocultas.\n",
    "\n",
    "\n",
    "* Utiizar una técnica como crossvalidation u otra similar para establecer la robustez del modelo.\n",
    "\n",
    "\n",
    "* Presentar métricas de desempeño para establecer las bondades y falencias de cada clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angel Ricardo Racini Meza\n",
    "### C.C 1017248189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leyendo el dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\ANGEL\\Desktop\\Trabajo Redes Neuronales\\evaluacion-arracinim\\SMSSpamCollection.txt\", sep = \"\\t\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se descargan las librerias necesarias para procesar el texto \n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesando los datos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio, se usará la libreria NLTK de Python. Con el fin de dividir cada frase en tokens semanticos de con los que se pueda sacar estadisticos como el promedio de verbos por mensajes, promedio de simbolos por mensajes, etc.\n",
    "\n",
    "Para esto se tiene que las palabras se pueden dividir en Articulos, Sustantivo, Pronombre, Adjetivo, verbo y adverbio. Además, para este caso se tendrán en cuenta tambien la cantidad de simbolos y numeros y la longitud total del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviendo el texto en una lista de tokens, clasificanco y sacando los promedios. \n",
    "lista = []\n",
    "for index, row in df.iterrows():\n",
    "    longitud = 0; verbo = 0; preposicion = 0; sustantivo = 0; pronombre = 0; adjetivo = 0; adverbio = 0\n",
    "    numero = 0; simbolo = 0; lista_tokenizada = []; Y = None\n",
    "\n",
    "    Y = row[0]\n",
    "    \n",
    "    #filtramos las stopwords o en español palabras vacias. \n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    word_tokens = nltk.word_tokenize(row[1]) \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    filtered_sentence = [] \n",
    "    for w in word_tokens: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w) \n",
    "\n",
    "    #Clasificamos el resto en las clasificaciones dadas\n",
    "    words = nltk.pos_tag(filtered_sentence)\n",
    "    longitud = len(words)\n",
    "\n",
    "    for word in words:\n",
    "        if word[1] == \"CD\":\n",
    "            numero += 1\n",
    "        elif word[1] == \"IN\" or word[1] == \"TO\":\n",
    "            preposicion += 1\n",
    "        elif word[1] == \"JJ\" or word[1] == \"JJR\" or word[1] == \"JJS\" or word[1] == \"JJ\":\n",
    "            adjetivo += 1\n",
    "        elif word[1] == \"NN\" or word[1] == \"NNP\" or word[1] == \"NNS\":\n",
    "            sustantivo += 1\n",
    "        elif word[1] == \"PRP\" or word[1] == \"PRP$\":\n",
    "            pronombre += 1\n",
    "        elif word[1] == \"RB\" or word[1] == \"RBR\" or word[1] == \"RBS\" or word[1] == \"JJ\":\n",
    "            adverbio += 1\n",
    "        elif word[1] == \"VB\" or word[1] == \"VBD\" or word[1] == \"VBG\" or word[1] == \"VBN\" or word[1] == \"VBP\" or word[1] == \"VBZ\":\n",
    "            verbo += 1\n",
    "        else:\n",
    "            simbolo += 1 \n",
    "        \n",
    "\n",
    "    lista_tokenizada = [longitud , verbo,  preposicion, pronombre, adjetivo , adverbio, \n",
    "    sustantivo, numero, simbolo, Y]\n",
    "    lista.append(lista_tokenizada)\n",
    "\n",
    "df_final = pd.DataFrame(data = lista, columns = ['longitud' , 'verbo',  'preposicion', 'pronombre', 'adjetivo' , 'adverbio', 'sustantivo', 'numero', 'simbolo', 'Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   longitud  verbo  preposicion  pronombre  adjetivo  adverbio  sustantivo  \\\n0        19      2            0          0         2         2           9   \n1         8      0            0          0         1         0           4   \n2        32      2            0          0         5         0          14   \n3        11      3            0          0         2         1           3   \n4        10      3            2          1         0         2           1   \n\n   numero  simbolo     Y  \n0       0        4   ham  \n1       0        3   ham  \n2       5        6  spam  \n3       0        2   ham  \n4       0        1   ham  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitud</th>\n      <th>verbo</th>\n      <th>preposicion</th>\n      <th>pronombre</th>\n      <th>adjetivo</th>\n      <th>adverbio</th>\n      <th>sustantivo</th>\n      <th>numero</th>\n      <th>simbolo</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>9</td>\n      <td>0</td>\n      <td>4</td>\n      <td>ham</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>ham</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>32</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>14</td>\n      <td>5</td>\n      <td>6</td>\n      <td>spam</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>ham</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>ham</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "source": [
    "#Vemos la estructura del nuevo dataframe \n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   longitud  verbo  preposicion  pronombre  adjetivo  adverbio  sustantivo  \\\n0        19      2            0          0         2         2           9   \n1         8      0            0          0         1         0           4   \n2        32      2            0          0         5         0          14   \n3        11      3            0          0         2         1           3   \n4        10      3            2          1         0         2           1   \n\n   numero  simbolo  Y  \n0       0        4  0  \n1       0        3  0  \n2       5        6  1  \n3       0        2  0  \n4       0        1  0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>longitud</th>\n      <th>verbo</th>\n      <th>preposicion</th>\n      <th>pronombre</th>\n      <th>adjetivo</th>\n      <th>adverbio</th>\n      <th>sustantivo</th>\n      <th>numero</th>\n      <th>simbolo</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>19</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>2</td>\n      <td>9</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>32</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>14</td>\n      <td>5</td>\n      <td>6</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "# Se procede a convertir el target a una variable binaria. \n",
    "df_final['Y'] = df_final['Y'].apply(lambda x: 1 if x == \"spam\" else 0)\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis descriptivo de las variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Copia de Untitled3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}